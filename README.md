# advanced-neural-net-library

An intensive, feature-rich deep learning library written completely in C++, along with python interface for user-friendly accessibility.

## Features

The following features are currently supported:

 * **Optimizers**: Features variety of optimizers like SGD, SGD with Momentum, SGD with Nesterov Momentum, Adagrad, Adam, Nadam, Adamax, AMSGrad, Adadelta, RMSProp, Adabound, AMSBound
 * **Activation functions**: Includes several activation functions such as Sigmoid, ReLU, Leaky ReLU, ELU, Tanh, Softmax
 * **Loss functions**: Supports various loss functions like Mean Absolute Error, Mean Squared Error, Quadratic, Half Quadratic, Cross Entropy, NLL
 * **Weight initializers**: Provides multiple weight initializers like Random, Xavier Uniform, Xavier Normal, LeCun Uniform, LeCun Normal, He Uniform, He Normal
 * **Regularizers**: Contains different regularizers such as L1, L2, L1L2, None
 * **Layers**: Fully Connected(Dense) Layer

## Example usage

The examples provided here give a general idea about creating, training, evaluating and performing operations like save/load on a model using both C++ and Python.

### C++

Detailed structure follows below:

* Creating a model
* Training a model
* Evaluating a model
* Saving and loading a model

### Python

Detailed structure follows below:

* Creating a model
* Compiling a model
* Traini