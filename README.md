# advanced-neural-net-library

An intensive, feature-rich deep learning library written completely in C++, along with python interface for user-friendly accessibility.

## Features

The following features are currently supported:

 * **Optimizers**: Features variety of optimizers like SGD, SGD with Momentum, SGD with Nesterov Momentum, Adagrad, Adam, Nadam, Adamax, AMSGrad, Adadelta, RMSProp, Adabound, AMSBound
 * **Activation functions**: Includes several activation functions such as Sigmoid, ReLU, Leaky ReLU, ELU, Tanh, Softmax
 * **Loss functions**: Supports various loss functions like Mean Absolute Error, Mean Squared Error, Quadratic, Half Quadratic, Cross Entropy, NLL
 * **Weight initializers**: Provides multiple weight initializers like Random, Xavier Uniform, Xavier Normal, LeCun Uniform, LeCun Normal, He Uniform, He Normal
 * **Regularizers**: Contain